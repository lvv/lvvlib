
LVV::ARRAY
==========

//  HTML rendered version of this file is at:  http://volnitsky.com/project/lvvlib/array

:gh-lvvlib:		httpx://github.com/lvv/lvvlib/tree/master/

include::summary.txt[]

lvv::array is just plain C-array wrapped in class. Wrapping adds zero memory and speed overhead.
As C-arrays the lvv::array is static-sized,  meaning "known at compile time size".

Quick Start
-----------

-----------------------------------------------
using lvv::array;

		// These are plain C++, not a C++0x constructors.
		// Second set of curly braces is optional, but 
		// some compilers issues warning if single set of braces is used.
array<float,3>	A = {{1., 2., 3.}};
array<float,3>	B;
array<float,3>	C = {{10., 20., 30.}};
array<float,3>	RES;

B   =  1.0;     // all elements are assigned `1.0f`
RES =  A+C;	// vector op
RES +=  B;	// vector op

		// you can send an array to iostream
cout  <<  "vector   A :   "  <<  A        << endl;
cout  <<  "vector   B :   "  <<  B        << endl;
cout  <<  "vector   C :   "  <<  C        << endl;
cout  <<  "vector RES :   "  <<  RES      << endl;
cout  <<  "dot product:   "  <<  dot(A,B) << endl;
------------------------------------

Output:
------------------------------------
vector   A :   1  2  3  
vector   B :   1  1  1  
vector   C :   10  20  30  
vector RES :   12  23  34  
dot product:   6
-------------------------------------


Speed
-----

Some operation were substantially  accelerated (explicitly specialized) using meta-programing,
explicit vectorisation (with SSE), parallel programming (with OpenMP), out of order optimization,  and some inline assembly. 
Below are some {gh-lvvlib}b-array.cc[benchmarks] on two-core, 2200Mhz Core2 Duo CPU:

=== array::sum()

["mpl", "speed-sum.png"]
-----------------------------------------
title('SUM - benchmark  lvv::array.sum()')
xlabel('CPU ticks per array element')
benchmark(c[0], c[1])
_________________________________________
'plain for-loop, double      ', 3.14
'plain for-loop, float       ', 3.06
'std::accumulate<float>()    ', 3.06
'lvv::array.sum()            ', 1.74
'lvv::array.sum<openmp>()    ', 1.67
-----------------------------------------

Tick refer to CPU tick and is about 0.45 nano seconds.
Sum was done for  100,000,000 float-s with values {1.f, 2.f, 1.f, 2.f, 1.f, 2.f ...}. Same benchmark is in below table: 

[cols="3,^2,^2, 16",frame="topbot",options="header"]
|============================================================================================
| *Method* 			| *Ticks per element* | *Computed Value*  | *Source*
| plain for-loop, double	| 3.14                | 1.5e+08           | `double sum=0;  for (int i=0; i<N; i++) sum += A[i];`
| plain for-loop, float		| 3.06                | 3.35e+07          | `float  sum=0;  for (int i=0; i<N; i++) sum += A[i];`
| std::accumulate<float>()	| 3.06                | 3.35e+07	  | `float  sum = accumulate(A.begin(), A.end(), 0.f));`
| lvv::array			| 1.74                | 1.5e+08           | `float  sum = A.sum();`
| lvv::array, explicit OpenMP	| 1.67                | 1.5e+08           | `float  sum = A.sum<openmp>();`
|============================================================================================

SSE method is selected (through meta-programming) if no summation method explicitly specified (if CPU supports SSE).
Note that float plain-for-loop and std::accumulate methods have incorrect computed values due to rounding error. 


=== array::max()

// Now benchmark for .max() method:

["mpl", "speed-max.png"]
-----------------------------------------
title('MAX -- lvv::array.max() benchmark')
xlabel('CPU ticks per array element')
benchmark(c[0], c[1])
_________________________________________
'plain for-loop		', 5.81
'std::max_element()	', 5.81
'SSE intrinsics		', 1.67
'lvv::array.sum()	', 1.63
-----------------------------------------
// RETEST:  'OpenMP			', 1.88

Maximum search was done on  100,000,000 float-s

[cols="2,^1,11",frame="topbot",options="header"]
|=======================================================================================================================
| *Method* 		| *Ticks per element* |   *Source*
| plain for-loop	| 5.81                | `float  max=0;  for (size_t i=0; i<N; i++) if (A[i] >  max) max = A[i];`
| std::max_element()	| 5.81                | `float  max = *std::max_element (A.begin(), A.end());`
| SSE intrinsics	| 1.67                | `__m128 m = mk_m128(A[0]);  for (size_t i=4; i<N; i+=4) { m = _mm_max_ps(m, mk_m128(A[i]) ); } ...`
| lvv::array 		| 1.63                | `float  max = A.max()`
|========================================================================================================================
//RETEST | OpenMP		| 1.88                | `(source same as above, 2xCPU, no check for race)`

So far I implemented only combinations needed for my work, so it is quite incomplete.
If there is no a type specialization then generic implementation is used.

.Implemented optimized specialisation
[cols="1,^1,^1,^1,^1",frame="topbot",options="header"]
|=============================================================
| *Type*         |  *sum*  | *max*  | *V1 OP= V2* | *V1 OP V2* 
| *generic*      |  std::  |  std:: | for-loop    | for-loop   
| *float*        | 'sse'   | 'sse'  | generic     | generic    
| *double*       | generic | generic| generic     | generic    
| *long double*  | generic | generic| generic     | generic    
| *int8_t*       | generic | generic| generic     | generic    
| *int16_t*      | generic | 'sse2' | generic     | generic    
| *int32_t*      | generic | generic| generic     | generic    
| *int64_t*      | generic | generic| generic     | generic            
| *uint8_t*      | generic | generic| generic     | generic           
| *uint16_t*     | generic | generic| generic     | generic           
| *uint32_t*     | generic | generic| generic     | generic           
| *uint64_t*     | generic | generic| generic     | generic           
|=============================================================

Though I've targeted only x86-64, some optimized specialisation (out-of-order,
meta-programming, OpenMP) are platform independent.
Appropriate specialisation selected automatically (but can be specified
explicitly) based on CPU capabilities, array size and array element type.


== Other lvv::array capabilities

- Index of first element defaults to 0, but can be any number (third template parameter).
- Index value for `opertator[]` tested if it is in valid range when `NDEBUG` macro  is not defined (not optimized compile). 
- basic linear algebra functions:  `norm2(A)`, `distance_norm2(A1,A2)`, `dot(A1,A2)`, etc

See also sample use in test files `t-*.cc` and unit test `u-array.cc`.

include::~/p/volnitsky.com/project/howto-submit-patch.txt[]

== References
- [[[1]]] http://www.ddj.com/cpp/184401967?pgno=1[Dr. Dobb's Journal: Optimizing C/C++ with Inline Assembly Programming.  June 01, 2005 ]
- [[[2]]] httpx://eigen.tuxfamily.org/index.php?title=Main_Page[Eigen 2 - C++ template library for linear algebra]
- [[[3]]] http://www.devx.com/cplus/Article/42114/1954?pf=true[std::array: The Secure, Convenient Option for Fixed-Sized Sequences]
- [[[4]]] httpx://www.research.att.com/~bs/C++0xFAQ.html#std-array[+++C++0x+++ - the next ISO C++ standard / atd::array]
- [[[5]]] Nicolai Josuttis -- httpx://boost.cowic.de/rc/pdf/array.pdf[Boost.Array] 
- [[[6]]] http://www.boost.org/doc/libs/1_37_0/doc/html/array.html[boost::array]
- [[[7]]] http://www.eld.leidenuniv.nl/~moene/Home/tips/matrix2d/[Three ways to allocate memory for a 2-dimensional matrix in C++]
- [[[8]]] Igor Ostrovsky -- http://igoro.com/archive/gallery-of-processor-cache-effects/[Gallery of Processor Cache Effects]
- [[[9]]] GCC Wiki -- http://gcc.gnu.org/wiki/Graphite/Parallelization[Automatic parallelization in Graphite]
- [[[10]]] WikiPedia -- http://en.wikipedia.org/wiki/Kahan_summation_algorithm[Kahan summation algorithm]

// vim:ft=asciidoc ts=8 sw=8:
